- Class: meta
  Course: Psychological Statistics You Can Handle
  Lesson: Mann-Whitney U-Tests
  Author: Kevin R. Carriere
  Type: Standard
  Organization: Washington & Jefferson College
  Version: 2.4.3

- Class: script
  Output: To save the notes for this module, copy and paste the code provided into your own RNotebook. Type submit() when you have finished saving these notes. 
  AnswerTests: script_results_identical('saved')
  Hint: "Don't change anything, just type submit(). If you did and you don't know how to fix it, just type skip(), and you'll be all set."
  Script: Notes.R
  
- Class: text
  Output: This module is the non-parametric alternative to the independent t-test module. You can also take the Testing for Non-Normality Module for additional review.

- Class: text
  Output: So, what does it mean to be non-parametric?
  
- Class: text
  Output: It means that it is a method of analysis that does not include assumptions regarding distributions. So, what assumptions are in the independent samples t-test?

- Class: text
  Output: "The assumptions of an independent samples t-test are - \n\n (1) The samples are randomly selected from the population. \n\n (2) The observations are independent from each other. \n\n (3) The sample mean is normally distributed between each population. \n\n (4) The variances between the two groups are equal."
  
- Class: text
  Output: That third and fourth assumptions -- normality of mean and equal variances - are things we can test. We reviewed how to test for equal variances in the independent samples t-test, and even include additional review in the module Welch's Two Sample T-Test when this assumption is violated. If neither are violated, we can proceed with the Independent Samples T-Test.

- Class: text
  Output: We are going to examine two papers within this Module, very briefly. In the first study, Dijkstra & Wessel (2021) examine the malleability of age estimates in earliest childhood memories through three experiments.

- Class: text
  Output: The citation for this paper is - Dijkstra, K., & Wessel, I. (2021). I remember having chicken pox at age 3- How can age manipulations affect one's earliest childhood memories? Collabra - Psychology, 7(1), 10.1525/collabra.21963.
  
- Class: text
  Output: We will examine Study 3, where participants were assigned to one of three conditions to test the effect of age manipulation on their earliest childhood memories.

#10
- Class: text
  Output: In the control condition,  Participants in this group were provided with an example memory that did not include any specific age reference. In the early condition, Participants in this group were provided with an example memory that included a reference to an early age (e.g., 2 years old). In the late condition, Participants in this group were given an example memory that referred to a later age (e.g., 6 years old).

- Class: text
  Output: Participants were asked to recall their earliest memory based on the given condition and complete a questionnaire about their memory.
  
- Class: cmd_question
  Output: Let's look at the data now by piping (|>) our dataset (memory) into head(). 
  CorrectAnswer: memory |> head()
  AnswerTests: omnitest(correctExpr='memory |> head()')
  Hint: Try memory |> head().

- Class: text
  Output: The authors end up comparing the differences between control and early, and control and late, conditions, using independent samples welch's t-test. They wrote in a footnote-- "The preregistered plan included additional non-parametric tests if skewness  or kurtosis > 1. This was the case for the early condition. An additional Mann-Whitney U test (Z = -3.13, p = .002) yielded a similar conclusion as the t-test."
  
- Class: text
  Output: We'll take their footnote one step at a time. First, kurtosis. This is a statistic that measures how much of one's data resides in the tails. Generally, these statistics are reported as +/- 3. So, why are the authors talking about 1? 
  
- Class: script
  Output: Edit the script we've provided.
  AnswerTests: script_results_identical('sumdata.kurtosis')
  Hint: Be sure to follow the instructions, and don't forget capitalization!
  Script: kurtosis.R
  
- Class: cmd_question
  Output: Great, print out your result by typing in sumdata.kurtosis into the Console now.
  CorrectAnswer: sumdata.kurtosis
  AnswerTests: omnitest(correctExpr='sumdata.kurtosis')
  Hint: Try sumdata.kurtosis.

- Class: text
  Output: We can see they used the psych::kurtosi package to report a kurtosis > 1. We don't want to get into the technicalities here, but you can generally notice how the first scores are roughly* 3 minus the second scores. 
  
- Class: text
  Output: Let's add one line to our script to get skew, which the authors note also is greater than 1. Skew represents how non-symmetrical the data is. 

- Class: script
  Output: Edit the script we've provided - it looks similar, but we've made one addition.
  AnswerTests: script_results_identical('sumdata.kurtosis')
  Hint: Be sure to follow the instructions, and don't forget capitalization!
  Script: skew.R
  
#20
- Class: cmd_question
  Output: Great, print out your result by typing in sumdata.kurtosis into the Console now.
  CorrectAnswer: sumdata.kurtosis
  AnswerTests: omnitest(correctExpr='sumdata.kurtosis')
  Hint: Try sumdata.kurtosis.

- Class: text
  Output: So it wasn't skewed by group, but we did have kurtosis.
  
- Class: text
  Output: Personally, we would have tested this using methods we've already learned - i.e., Shapiro-Wilk, QQPlots, Histograms. We go over these in great detail in Wilcoxon-Signed Rank Test.

- Class: text
  Output: Shapiro-Wilk tests if the distribution is normal. Our null hypothesis is that the data is normal, and if p<.05, then we reject the null hypothesis that the distribution is normal.

- Class: cmd_question
  Output: We show two ways to run Shapiro-Wilk tests in the Notes, but in this module, we'll focus on the rstatix version, shapiro_test(). Take our data, memory, and pipe it into group_by(), which should take the argument condition, and then pipe that into shapiro_test(), with a single argument, age_recall.
  CorrectAnswer: memory |> group_by(condition) |> shapiro_test(age_recall)
  AnswerTests: omnitest(correctExpr='memory |> group_by(condition) |> shapiro_test(age_recall)')
  Hint: Try memory |> group_by(condition) |> shapiro_test(age_recall).

- Class: text
  Output: And we would have come to a similar conclusion. We generally advise using all tools - Shapiro-Wilk, histograms, and qqplots - to examine our assumptions. Perhaps you can add skew and kurtosis to your arsenal too.
  
- Class: text
  Output: Okay, so what's next. As a reminder, they write - "This was the case for the early condition. An additional Mann-Whitney U test (Z = -3.13, p = .002) yielded a similar conclusion as the t-test."

- Class: cmd_question
  Output: Let's pipe our dataset, memory, into wilcox.test(). It will take two arguments -- the equation, or age_recall ~ ContvEarly, and  data=_ . And this time, let's save it as mwu_result. Try that now.
  CorrectAnswer: mwu_result <- memory |> wilcox.test(age_recall ~ ContvEarly, data=_)
  AnswerTests: omnitest(correctExpr='mwu_result <- memory |> wilcox.test(age_recall ~ ContvEarly, data=_)')
  Hint: Try mwu_result <- memory |> wilcox.test(age_recall ~ ContvEarly, data=_)

- Class: cmd_question
  Output: Great, print out your result by typing in mwu_result into the Console now.
  CorrectAnswer: mwu_result
  AnswerTests: omnitest(correctExpr='mwu_result')
  Hint: Try mwu_result
  
- Class: text
  Output: We got the p-value, but we have a huge W score and they have a small Z statistic! How do we get the Z-statistic?
 
#30 
- Class: mult_question
  Output: If you were to type mwu_result$ into your console without hitting enter, a list of possible variables would show up. Which of the following does not appear? 
  AnswerChoices: statistic; parameter; p.value; null.value; alternative; method; data.name; sign
  CorrectAnswer: sign
  AnswerTests: omnitest(correctVal='sign')
  Hint: You can also click the arrow in your Environment next to mwu_result and see the list there!

- Class: cmd_question
  Output: Save a new object, called mwu_resultp, and have it be set as mwu_result$p.value . 
  CorrectAnswer: mwu_resultp <- mwu_result$p.value
  AnswerTests: omnitest(correctExpr='mwu_resultp <- mwu_result$p.value')
  Hint: Try mwu_resultp <- mwu_result$p.value

- Class: cmd_question
  Output: Now that we see how even something as simple as a function call also creates variables (similar to a data frame in some ways), we can pass mwu_resultp through qnorm(). However, inside, divide that argument by two because we want a two-tailed test. That will get us our Z statistic.
  CorrectAnswer: qnorm(mwu_resultp/2)
  AnswerTests: omnitest(correctExpr='qnorm(mwu_resultp/2)')
  Hint: qnorm(mwu_resultp/2)

- Class: text
  Output: You can also treat the Wilcoxon signed rank test as a one-sample test. 
  
- Class: text
  Output: "The next paper explored the association between individuals' ability to accurately forecast conflict outcomes and their past and current experiences with violence. The study was conducted with 127 Netherlands participants, including a community sample and college students. a Wilcoxon signed-rank test was used to determine whether participants could accurately discriminate between signal (fight) and no-signal (no-fight) trials. The parameter d’ was used as a measure of accuracy, with a higher d’ indicating greater accuracy."

- Class: text
  Output: The citation for this paper is Frankenhuis, W. E., Weijman, E. L., de Vries, S. A., van Zanten, M., & Borghuis, J. (2022). Exposure to violence is not associated with accuracy in forecasting conflict outcomes. Collabra- Psychology, 8(1) doi.org/10.1525/collabra.38604
- Class: text
  Output: They write - "A Wilcoxon signed rank test indicated that the average d’ (M = .21, SE = .05)  was significantly higher than zero (W = 3307.50, p < .001).   This indicates that on average for the two samples combined, participants did better than chance."

- Class: cmd_question
  Output: Let's get that output. The data is loaded as violence. Take our data, violence, and pipe it into  wilcox.test(), passing two arguments. First, the equation, which since it is a one-sample test, has no group, so we write dprime ~ 1, and the second argument, data=_ .
  AnswerTests: omnitest(correctExpr='violence |> wilcox.test(dprime ~ 1, data=_)')
  CorrectAnswer: violence |> wilcox.test(dprime ~ 1, data=_)
  Hint: violence |> wilcox.test(dprime ~ 1, data=_)
  
- Class: cmd_question
  Output: While the comparison is set at default to 0, you can set the comparison to any number - for example, is some scale less than or equal to the median (3.5 on a 7 point scale?). Hit the up arrow, and include a third argument in your wilcox.test() that says mu=3.5 . 
  AnswerTests: omnitest(correctExpr='violence |> wilcox.test(dprime ~ 1, data=_, mu=3.5)')
  CorrectAnswer: violence |> wilcox.test(dprime ~ 1, data=_, mu=3.5)
  Hint: violence |> wilcox.test(dprime ~ 1, data=_, mu=3.5)












  
  
  
