- Class: meta
  Course: Psychological Statistics You Can Handle
  Lesson: One Sample T-Test
  Author: Kevin R. Carriere, Jason Kilgore
  Type: Standard
  Organization: Washington & Jefferson College
  Version: 3.0.0

- Class: script
  Output: Here are some notes for this module. When you've saved the notes, type submit().
  AnswerTests: script_results_identical('saved')
  Hint: Make sure the last line in your script says saved <- "Y".
  Script: Notes.R

- Class: figure
  Output: The one-sample t-test is straightforward in mathematical terms. We have our sample mean, xbar, and we want to test if there is a difference between xbar and a hypothesized mean, mu. We calculate that by dividing that difference by the standard deviation divided by the square root of N, known as the standard error.
  Figure: onesamplettest.R
  FigureType: New
  
- Class: text
  Output: "There are two main assumptions for a one-sample t-test. \n\n (1) The data is randomly sampled from the population. \n\n (2) The variable is normally distributed in the population."

- Class: text
  Output: In psychology, we generally utilize a one-sample t-test to compare against a scale midpoint to show more agreement with some hypothesized value, e.g. how much you like a digital service (1 to 7; Bad = 1; 7 = good; midpoint at 3 = neutral)."


- Class: text
  Output: In one study, researchers wanted to test how people thought about their purchases and how they define them.

- Class: text
  Output: "The citation for this study is - Chen, E. Y., Chee, M. X., & Feldman, G. (2023). Revisiting the Differential Centrality of Experiential and Material Purchases to the Self- Replication and Extension of Carter and Gilovich (2012). Collabra: Psychology, 9(1), 57785. doi.org/10.1525/collabra.57785"
  
- Class: text
  Output: "The prompt to the participants read - Please imagine two people, one of whom knew all about your material purchases (Person M), and the other knew all about your experiential purchases (Person E), but neither knew anything else about you. \n\n Which person would better know the real you, your true, essential self? (1 = Definitely Person M (material), 5 = Both equally, 9 = Definitely Person E (experiential))."
  
- Class: text
  Output: They write - "We conducted a one-sample t-test (two-tailed) against the scale midpoint of 5. Consistent with H1, we found that a person with experiential purchase knowledge is perceived to have a greater insight into one’s true self than a person with material purchase knowledge (M = 6.43, SD = 2.22, t(742) = 17.61, p < .001, d = 0.65, 95% CI [0.57, 0.73])."

#10
- Class: cmd_question
  Output: We have a function t.test() to run this test. We will pipe (|>) our dataset (purchases) into t.test(), passing three arguments into it -- MPEP_self ~ 1, mu=5, and data=_ . MPEP_self ~ 1 asks for a one-sample t-test because we are comparing the variable against no comparison group (signified by the 1). mu=5 says that our hypothesized mean is five that we are comparing against, and data=_ is our reference for the data on the left-hand side of the pipe. Run this now.
  CorrectAnswer: purchases |> t.test(MPEP_self ~ 1, mu=5, data=_)
  AnswerTests: omnitest(correctExpr='purchases |> t.test(MPEP_self ~ 1, mu=5, data=_)')
  Hint: purchases |> t.test(MPEP_self ~ 1, mu=5, data=_)
  
- Class: text
  Output: That got us all of the information besides the effect size and the confidence interval of the effect size.

- Class: cmd_question
  Output: We have a function cohens_d() from the rstatix package to get those results. We will pipe (|>) our dataset (purchases) into cohens_d() with three arguments - MPEP_self ~ 1 (just like our t.test), mu=5 (again, the same), and ci=TRUE. Our notes give a list of other ways to code this, as well as other packages.
  CorrectAnswer: purchases |>  cohens_d(MPEP_self ~ 1, mu=5, ci=TRUE)
  AnswerTests: omnitest(correctExpr='purchases |>  cohens_d(MPEP_self ~ 1, mu=5, ci=TRUE)')
  Hint: purchases |>  cohens_d(MPEP_self ~ 1, mu=5, ci=TRUE)

- Class: text
  Output: However, there are times when we cannot satisfy the second assumption of the one-sample t-test -- that the data is not normally distributed in the population (or we are not sure).
  
- Class: text
  Output: We can turn to a non-parametric test in times like these.  
  
- Class: text
  Output: In 2022, Frankenhuis and colleagues wanted to know whether or not individuals who lived in relatively challenging conditions were significantly different in a range of measures compared to those who lived in low-risk situations, with their primary research question measuring if those who were high-risk detected more threats in ambiguous situations compared to a low-risk group.

- Class: text
  Output: The high-risk group was a "group of community participants who lived in relatively challenging conditions for Dutch standards, in that people were more likely to need governmental support to meet their basic needs (e.g., food, housing, safety)." They had "anticipated that on average members of the community sample had experienced higher levels of adversity, including higher levels of exposure to violence in their past or current environments. The other group was a college student sample, who [were] expected to have experienced lower levels of violence (the ‘low-risk group’)". We've loaded their data in your environment under violence.

- Class: text
  Output: "The citation for this paper is- Frankenhuis, W. E., Weijman, E. L., de Vries, S. A., van Zanten, M., & Borghuis, J. (2022). Exposure to Violence Is Not Associated With Accuracy in Forecasting Conflict Outcomes. Collabra- Psychology, 8(1), 38604. doi.org/10.1525/collabra.38604"

- Class: text
  Output: Participants watched 16 videos of real-life conflicts and were asked to judge whether each would lead to a physical fight. The researchers (but not the participants) knew that half of those conflicts ended in fights, while half did not. One of their measures in this dataset is C. 
  
- Class: text
  Output: "Criterion c represents the threshold for recognizing a signal (i.e., fight) trial: a c of zero indicates no bias, a negative c a low threshold (fight bias; consistent with hostile attribution bias), and a positive c a high threshold (no-fight bias; consistent with rose-colored glasses.)."

#20
- Class: text
  Output: So, they would hypothesize that those in the high-risk group may have a lower C score (and be fight-biased) while low-risk would be expected to have either no or no-fight bias. 
  
- Class: cmd_question
  Output: Look at the data now by running violence |> summary().
  CorrectAnswer: violence |> summary()
  AnswerTests: omnitest(correctExpr='violence |> summary()')
  Hint: Try violence |> summary()

- Class: text
  Output: There are a variety of ways in which we can test to see if the variable is normally distributed.
  
- Class: figure
  Output: For example, we could plot the distribution of our variable, C, on a histogram. The line that is shown is the median. There is a positive skew in our variable. We include more information about this in the Notes.
  Figure: Figure1.R
  FigureType: new

- Class: text
  Output: However, the Shapiro-Wilk test is one of the most well-known and used tests for non-normality. It is very limited - small sample sizes cause it to have not enough power to detect non-normality. Still, too large sample sizes will also be rejected for non-normality. 
 
- Class: text
  Output: There are other tests, such as the Kolmogorov-Smirnov test, but Shapiro-Wilk has been demonstrated to have the most power, so we focus purely on Shapiro-Wilk.

- Class: text
  Output: For more information, see Razali, N. M., Wah, Y. B. (2011). Power comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors, and Anderson-Darling tests. Journal of Statistical Modeling and Analytics. 2(1), 21-33.

- Class: cmd_question
  Output: The function for Shapiro-Wilk is shapiro_test() in the rstatix package. Let's practice our piping technique, so take violence and |> pipe it into shapiro_test(), passing the single argument C .
  CorrectAnswer: violence |> shapiro_test(C)
  AnswerTests: omnitest(correctExpr='violence |> shapiro_test(C)')
  Hint: violence |> shapiro_test(C)

- Class: text
  Output: The null hypothesis is that there is no difference between the distribution of the variable and the normal distribution. If we find sufficient evidence to reject that null hypothesis (conventionally, at an alpha of .05), then we reject the hypothesis that there is no difference between the distribution of the variable and the normal distribution.
  
- Class: text
  Output: Great job. So, indeed, our variable is non-normal. 

- Class: text
  Output: "They write - A Wilcoxon signed rank test showed that the average c (M = .11, SE = .04) also was significantly higher than zero (W = 4044.5, p = .018)."

- Class: text
  Output:  Let's first practice our one sample Wilcoxon sign-ranked test. Since there is no predictor, we need to tell R that we are passing what is known as a null model - there are no predictors. We want to see if C is greater than zero.
  
- Class: cmd_question
  Output: To do that, take our dataset, violence, and pipe (|>) into the wilcox_test() function from the rstatix library, passing two arguments - C ~ 1 and mu=0. (mu=0 is the default, but it's good practice to know what we're doing).
  CorrectAnswer: violence |> wilcox_test(C ~ 1, mu=0)
  AnswerTests: omnitest(correctExpr='violence |> wilcox_test(C ~ 1, mu=0)')
  Hint: violence |> wilcox_test(C ~ 1, mu=0)

- Class: script
  Output: The first part of their sentence called out the mean and standard error. Let's calculate those now. We've loaded a script for you to fill out to solve for the mean and standard error.
  AnswerTests: script_results_identical('sum_violence')
  Hint: Follow the notes in the script, and be sure you saved your script (using the save button or ctrl+S) before typing submit() in the Console.
  Script: summarise.R

- Class: cmd_question
  Output: Print out the results of your script in the console now by typing in sum_violence.
  CorrectAnswer: sum_violence
  AnswerTests: omnitest(correctExpr='sum_violence')
  Hint: Type sum_violence.

- Class: text
  Output: They next write - "Separate tests for each group indicated that c did not differ significantly from zero in the community sample (W = 871.50, p = .723) [Hypothesis 2],"
  
- Class: cmd_question
  Output: To do this, hit the up arrow on your console until you return to your wilcox_test(). We want to add one more step between the dataset and wilcox_test(). After the first pipe, let us filter() where risk_group should equal (==) "High-risk group". Then pipe that filter (|>) into the wilcox_test().
  CorrectAnswer: violence |> filter(risk_group=="High-risk group") |> wilcox_test(C ~ 1)
  AnswerTests: omnitest(correctExpr='violence |> filter(risk_group=="High-risk group") |> wilcox_test(C ~ 1)')
  Hint: violence |> filter(risk_group=="High-risk group") |> wilcox_test(C ~ 1)

- Class: text
  Output: Finally, they write - "but was significantly higher than zero in the student sample (W = 1169.50, p = .002) [Hypothesis 3]."
  
- Class: cmd_question
  Output: To do this, hit the up arrow on your console. Now, we need to change that filter to "Low-risk group".
  CorrectAnswer: violence |> filter(risk_group=="Low-risk group") |> wilcox_test(C ~ 1)
  AnswerTests: omnitest(correctExpr='violence |> filter(risk_group=="Low-risk group") |> wilcox_test(C ~ 1)')
  Hint: violence |> filter(risk_group=="Low-risk group") |> wilcox_test(C ~ 1)
  
- Class: text
  Output: Great job. Now you have some practice and notes about one sample tests, including the one sample t-test and the Wilcoxon signed-rank test.
  
